# ===============================
# services/llm-service/requirements.txt
# ===============================
# requirements.txt بدون torch:
# fastapi==0.115.4
# uvicorn[standard]==0.32.1
# transformers==4.46.3
accelerate==1.1.1
# sentencepiece==0.2.0
# tokenizers==0.20.3
# pydantic==2.10.3
# psutil==6.1.0
# prometheus-client==0.21.1
# aiofiles==24.1.0
# python-multipart==0.0.12


# Core dependencies
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0

# Machine Learning
transformers==4.36.0
tokenizers==0.15.0
# torch==2.1.0 (installed separately in Dockerfile)

# GPU utilities (optional)
GPUtil==1.4.0

# HTTP client for GPU coordination
httpx==0.25.2

# System monitoring
psutil==5.9.6

# Metrics
prometheus-client==0.19.0

# Other utilities
python-multipart==0.0.6
aiofiles==23.2.1