# .env
# Environment Configuration for Agentic AI Platform
# ===================================================
COMPOSE_CONVERT_WINDOWS_PATHS=1
# Environment
ENV=development
DEBUG=true
LOG_LEVEL=INFO

# GPU
PRELOAD_LLM_MODEL=false
PRELOAD_STT_MODEL=false
# ===================================================
# Database Configuration
# ===================================================
DATABASE_URL=postgresql://postgres:password@postgres:5432/agentic_db
POSTGRES_DB=agentic_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password
POSTGRES_PORT=5433

# ===================================================
# Redis Configuration
# ===================================================
REDIS_URL=redis://redis:6379

# ===================================================
# Service Ports & Hosts
# ===================================================
# API Gateway
API_GATEWAY_PORT=8000
API_GATEWAY_HOST=0.0.0.0

# LLM Service
LLM_SERVICE_PORT=8002
LLM_SERVICE_HOST=0.0.0.0

# STT Service (Audio Service)
STT_SERVICE_PORT=8003
STT_SERVICE_HOST=0.0.0.0

# GPU Coordinator
GPU_COORDINATOR_PORT=8080
GPU_COORDINATOR_HOST=0.0.0.0

# Auth Service
AUTH_SERVICE_PORT=8004
AUTH_SERVICE_HOST=0.0.0.0

# Test Service
TEST_SERVICE_PORT=8001
TEST_SERVICE_HOST=0.0.0.0

# ===================================================
# LLM Service Configuration
# ===================================================
MODEL_PATH=/app/models/llm/gpt2-fa
MODEL_NAME=gpt2-fa
MAX_LENGTH=512
BATCH_SIZE=1

# LLM Performance Settings
LLM_WORKERS_COUNT=1
LLM_WORKER_TIMEOUT=300
LLM_MAX_CONCURRENT_REQUESTS=3

# ===================================================
# STT Service Configuration  
# ===================================================
WHISPER_MODEL_SIZE=medium
WHISPER_MODEL_PATH=/app/models/stt
WHISPER_MODEL=medium

# STT Performance Settings
MAX_FILE_SIZE_MB=25
MAX_CONCURRENT_REQUESTS=5
SUPPORTED_LANGUAGES=fa,en
CACHE_ENABLED=true
CACHE_TTL=3600

# Audio Processing
SUPPORTED_AUDIO_FORMATS=wav,mp3,m4a,flac,ogg
MAX_AUDIO_LENGTH_SECONDS=300

# ===================================================
# GPU Configuration & Sharing
# ===================================================
CUDA_VISIBLE_DEVICES=0
GPU_MEMORY_FRACTION=0.8
MAX_MEMORY_MB=6144
SCHEDULER_INTERVAL=1

# GPU Allocation Strategy
GPU_ALLOCATION_STRATEGY=round_robin
LLM_GPU_MEMORY_RESERVE=3072
STT_GPU_MEMORY_RESERVE=2048
GPU_MEMORY_BUFFER=1024

# Performance Optimization
MIXED_PRECISION=true
ENABLE_CUDA_GRAPHS=false

# ===================================================
# Service URLs (Internal Communication)
# ===================================================
LLM_SERVICE_URL=https://llm-service:8002
STT_SERVICE_URL=https://stt-service:8003
AUTH_SERVICE_URL=https://auth-service:8004
API_GATEWAY_URL=https://api-gateway:8000
GPU_COORDINATOR_URL=https://gpu-coordinator:8080

# ===================================================
# Authentication & Security
# ===================================================
JWT_SECRET_KEY=your-super-secret-jwt-key-change-this-in-production-please-2024
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24
ACCESS_TOKEN_EXPIRE_MINUTES=30

# API Security
RATE_LIMIT_PER_MINUTE=60
MAX_REQUEST_SIZE_MB=100

# ===================================================
# CORS Configuration
# ===================================================
ALLOWED_ORIGINS=https://localhost:3000,https://localhost:8080,https://localhost:8000,https://localhost

# ===================================================
# File Upload & Storage
# ===================================================
UPLOAD_DIR=./data/uploads
MAX_FILE_SIZE_MB=100
ALLOWED_FILE_TYPES=wav,mp3,m4a,flac,ogg,txt,json

# Cleanup Settings
AUTO_CLEANUP_UPLOADS=true
CLEANUP_INTERVAL_HOURS=24
MAX_STORAGE_GB=50

# ===================================================
# AI Model Configurations
# ===================================================
# Hugging Face
HUGGINGFACE_TOKEN=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
HUGGINGFACE_CACHE_DIR=/app/cache/huggingface

# Model Loading
MODEL_LOADING_TIMEOUT=300
PRELOAD_MODELS=true
MODEL_CACHE_SIZE=2

# ===================================================
# Monitoring & Observability
# ===================================================
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
GRAFANA_ADMIN_PASSWORD=admin

# Metrics Collection
ENABLE_METRICS=true
METRICS_INTERVAL=30
HEALTH_CHECK_INTERVAL=10

# ===================================================
# External Services (Optional)
# ===================================================
# Ollama (if used)
OLLAMA_BASE_URL=https://localhost:11434
OLLAMA_ENABLED=false

# Vector Database (for future)
VECTOR_DB_URL=https://localhost:6333
VECTOR_DB_ENABLED=false

# Message Queue (for future)
RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
MESSAGE_QUEUE_ENABLED=false

# ===================================================
# Docker & Infrastructure
# ===================================================
# Nginx Ports
NGINX_HTTP_PORT=80
NGINX_HTTPS_PORT=443

# Container Resources
CONTAINER_MEMORY_LIMIT=8g
CONTAINER_CPU_LIMIT=4

# ===================================================
# Development & Debugging
# ===================================================
RELOAD=false
ACCESS_LOG=true
ENABLE_PROFILING=false

# Development Tools
HOT_RELOAD=false
DEBUG_GPU=false
VERBOSE_LOGGING=false

# Testing
TEST_MODE=false
MOCK_GPU=false

# ===================================================
# Performance Tuning
# ===================================================
WORKERS_COUNT=1
WORKER_TIMEOUT=300
KEEPALIVE_TIMEOUT=2
MAX_CONNECTIONS=1000

# Connection Pools
DB_POOL_SIZE=20
REDIS_POOL_SIZE=10

# ===================================================
# Feature Flags
# ===================================================
ENABLE_LLM=true
ENABLE_STT=true
ENABLE_GPU_SHARING=true
ENABLE_AUTH=true
ENABLE_RATE_LIMITING=true
ENABLE_CACHING=true

# Experimental Features
ENABLE_BATCH_PROCESSING=false
ENABLE_MODEL_QUANTIZATION=false
ENABLE_STREAMING=true

# ===================================================
# Backup & Recovery (for future)
# ===================================================
BACKUP_ENABLED=false
BACKUP_INTERVAL_HOURS=24
BACKUP_RETENTION_DAYS=7

# ===================================================
# TTS Configuration (for future expansion)
# ===================================================
TTS_MODEL=tts_models/en/ljspeech/tacotron2-DDC
TTS_ENABLED=false
TTS_SERVICE_PORT=8005