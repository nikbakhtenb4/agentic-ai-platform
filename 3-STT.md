services/audio-service/stt/
โโโ main.py # FastAPI application
โโโ Dockerfile # Container setup
โโโ requirements.txt # Dependencies
โโโ config/
โ โโโ stt_config.yaml # Configuration
โโโ models/
โ โโโ whisper_handler.py # Whisper model management
โโโ utils/
โ โโโ audio_processor.py # Audio processing
โ โโโ gpu_coordinator.py # Shared GPU management
โ โโโ cache_manager.py # Caching system
โโโ schemas/
โโโ stt_schemas.py # Pydantic models

๐ ูฺฺฏโูุง ูพุงุฏูโุณุงุฒ ุดุฏู:

Whisper Integration: ุงุณุชูุงุฏู ุงุฒ ูุฏู Whisper ุจุฑุง STT
Multi-language: ูพุดุชุจุงู ูุงุฑุณ ู ุงูฺฏูุณ
Audio Processing: ูพุฑุฏุงุฒุด ูพุดุฑูุชู ุตูุช
Batch Processing: ูพุฑุฏุงุฒุด ฺูุฏู ูุงู ููุฒูุงู
GPU Acceleration: ุจูุฑูโฺฏุฑ ุงุฒ GPU
Docker & Kubernetes: ุขูุงุฏู ุจุฑุง deployment
Error Handling: ูุฏุฑุช ุฎุทุง ู logging ฺฉุงูู

๐ API Endpoints:
POST /stt/transcribe - ุชุจุฏู ุชฺฉ ูุงู ุตูุช
POST /stt/transcribe-batch - ุชุจุฏู ฺูุฏู ูุงู
GET /stt/languages - ุฒุจุงูโูุง ูพุดุชุจุงู ุดุฏู  
GET /stt/health - ูุถุนุช ุณุฑูุณ
ุชุบุฑุงุช ุจุฑุง ูพุดุชุจุงู ููุจุงู/ูุจ:
โ ูุงุจูุชโูุง ุงุถุงูู ุดุฏู:

CORS Configuration: ุจุฑุง ุฏุณุชุฑุณ ุงุฒ ูุฑูุฑฺฏุฑ
Base64 Audio Support: ุจุฑุง ุงุฑุณุงู ุตุฏุง ุงุฒ ููุจุงู ุงูพ
Enhanced File Upload: ูพุดุชุจุงู ูุฑูุชโูุง ุจุดุชุฑ
Better Error Handling: ูพุงูโูุง ุฎุทุง ูุงุถุญโุชุฑ
File Size Validation: ฺฺฉ ุณุงุฒ ูุงู ุจุฑุง ููุจุงู
Options Handler: ูพุดุชุจุงู CORS preflight

๐ API Endpoints ุจุฑุง ููุจุงู/ูุจ:
bash# ุจุฑุง ูุจ (ูุงู ุขูพููุฏ)
POST /stt/transcribe

# ุจุฑุง ููุจุงู (Base64)

POST /stt/transcribe-base64

# ุจุฑุง ูพุฑุฏุงุฒุด ฺูุฏุชุง

POST /stt/transcribe-batch

# ุงุทูุงุนุงุช ุณุฑูุณ

GET /stt/languages
GET /stt/health
๐ฑ ููููู ุงุณุชูุงุฏู ุงุฒ ููุจุงู:
javascript// React Native / Mobile App
const uploadAudio = async (audioBase64, filename) => {
const response = await fetch('/api/stt/transcribe-base64', {
method: 'POST',
headers: {
'Content-Type': 'application/json',
},
body: JSON.stringify({
audio_data: audioBase64,
filename: filename,
language: 'fa', // ุง 'en'
format: 'wav'
})
});

return await response.json();
};
๐ ููููู ุงุณุชูุงุฏู ุงุฒ ูุจ:
javascript// Web App
const uploadAudioFile = async (file, language) => {
const formData = new FormData();
formData.append('audio_file', file);
formData.append('language', language);

const response = await fetch('/api/stt/transcribe', {
method: 'POST',
body: formData
});

return await response.json();
};

---

# ุฑุงูููุง ฺฉุงูู ุฑุงูโุงูุฏุงุฒ ุณุณุชู Agentic AI Platform ุจุง STT

## ๐ ููุฑุณุช ูุทุงูุจ

1. [ูุนุฑู ุณุณุชู](#ูุนุฑู-ุณุณุชู)
2. [ูพุดโูุงุฒูุง](#ูพุดโูุงุฒูุง)
3. [ุณุงุฎุชุงุฑ ูพุฑูฺู](#ุณุงุฎุชุงุฑ-ูพุฑูฺู)
4. [ุฑุงูโุงูุฏุงุฒ](#ุฑุงูโุงูุฏุงุฒ)
5. [ุณุฑูุณโูุง ููุฌูุฏ](#ุณุฑูุณโูุง-ููุฌูุฏ)
6. [ุชุณุช ู ุงุณุชูุงุฏู](#ุชุณุช-ู-ุงุณุชูุงุฏู)
7. [ูุงูุชูุฑูฺฏ](#ูุงูุชูุฑูฺฏ)
8. [ุนุจโุงุจ](#ุนุจโุงุจ)

## ๐ ูุนุฑู ุณุณุชู

ุณุณุชู Agentic AI Platform ฺฉ ูพูุชูุฑู ฺฉุงูู ููุด ูุตููุน ุงุณุช ฺฉู ุดุงูู ุณุฑูุณโูุง ุฒุฑ ูโุจุงุดุฏ:

### โจ ูฺฺฏโูุง ฺฉูุฏ

- **LLM Service**: ุณุฑูุณ ุชููุฏ ูุชู ุจุง ูุฏู GPT2-FA ูุงุฑุณ
- **STT Service**: ุณุฑูุณ ุชุจุฏู ฺฏูุชุงุฑ ุจู ูุชู ุจุง Whisper
- **GPU Coordinator**: ูุฏุฑุช ูุดุชุฑฺฉ ููุงุจุน GPU ุจู ุณุฑูุณโูุง
- **API Gateway**: ูุฏุฑุช ูุฑฺฉุฒ API ูุง
- **Monitoring**: ูุงูุชูุฑูฺฏ ฺฉุงูู ุจุง Prometheus ู Grafana

### ๐ฏ ูุงุจูุชโูุง STT Service

- ูพุดุชุจุงู ุงุฒ ุฒุจุงูโูุง ูุงุฑุณ ู ุงูฺฏูุณ
- ูพุฑุฏุงุฒุด ูุงูโูุง ุตูุช ูุชููุน (WAV, MP3, M4A, FLAC, OGG, WebM)
- ูพุฑุฏุงุฒุด Base64 ุจุฑุง ุงูพูฺฉุดูโูุง ููุจุงู
- ูพุฑุฏุงุฒุด ุฏุณุชูโุง (Batch Processing)
- ฺฉุด ฺฉุฑุฏู ูุชุงุฌ ุจุฑุง ุจูุจูุฏ ฺฉุงุฑุง
- ูพุฑุฏุงุฒุด ู ุจูุจูุฏ ฺฉูุช ุตุฏุง
- ูุฏุฑุช GPU ูุดุชุฑฺฉ ุจุง ุณุงุฑ ุณุฑูุณโูุง

## ๐ ูพุดโูุงุฒูุง

### ุณุณุชู ุนุงูู

- Windows 10/11ุ Linuxุ ุง macOS
- ุญุฏุงูู 16GB RAM (32GB ุชูุตู ูโุดูุฏ)
- ุญุฏุงูู 50GB ูุถุง ุฎุงู ุฏุณฺฉ
- GPU NVIDIA ุจุง ุญุฏุงูู 6GB VRAM (ุงุฎุชุงุฑ ุงูุง ุชูุตู ูโุดูุฏ)

### ูุฑูโุงูุฒุงุฑูุง ููุฑุฏ ูุงุฒ

- Docker Desktop
- Docker Compose V2
- Python 3.11+ (ุจุฑุง ุชุณุช)
- Git
- NVIDIA Container Toolkit (ุจุฑุง ุงุณุชูุงุฏู ุงุฒ GPU)

### ูุฏูโูุง ููุด ูุตููุน

- ูุฏู GPT2-FA ูุงุฑุณ ุฏุฑ ูุณุฑ `data/models/llm/gpt2-fa/`
- ูุฏู Whisper (ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ ุฏุงูููุฏ ูโุดูุฏ)

## ๐ ุณุงุฎุชุงุฑ ูพุฑูฺู

```
agentic-ai-platform/
โโโ docker-compose.yml
โโโ nginx.conf
โโโ .env
โโโ setup.py
โโโ data/
โ   โโโ models/
โ   โ   โโโ llm/gpt2-fa/
โ   โ   โโโ stt/
โ   โโโ cache/
โ   โโโ logs/
โ   โโโ uploads/
โโโ services/
โ   โโโ api-gateway/
โ   โโโ llm-service/
โ   โโโ audio-service/stt/
โ   โโโ gpu-coordinator/
โ   โโโ test-service/
โโโ monitoring/
โ   โโโ prometheus.yml
โ   โโโ grafana/
โโโ shared/
โ   โโโ database/init.sql
โโโ tests/
    โโโ stt_test_client.py
```

## ๐ ุฑุงูโุงูุฏุงุฒ

### ฺฏุงู 1: ฺฉููู ู ุขูุงุฏูโุณุงุฒ

```bash
# ฺฉููู ูพุฑูฺู
git clone <repository-url>
cd agentic-ai-platform

# ุงุฌุงุฏ ุฏุงุฑฺฉุชูุฑโูุง ููุฑุฏ ูุงุฒ
mkdir -p data/models/llm/gpt2-fa
mkdir -p data/models/stt
mkdir -p data/cache/stt
mkdir -p data/logs
mkdir -p data/uploads

# ฺฉูพ ูุฏู GPT2-FA
# ูุงูโูุง ูุฏู ุฑุง ุฏุฑ data/models/llm/gpt2-fa/ ูุฑุงุฑ ุฏูุฏ
```

### ฺฏุงู 2: ุชูุธู ูุญุท

```bash
# ฺฉูพ ูุงู environment
cp .env.example .env

# ูุฑุงุด ูุชุบุฑูุง ูุญุท ุฏุฑ ุตูุฑุช ูุงุฒ
# nano .env
```

### ฺฏุงู 3: ุฑุงูโุงูุฏุงุฒ ุจุง Docker

```bash
# ุจูุฏ ู ุงุฌุฑุง ุณุฑูุณโูุง
docker compose up --build -d

# ูุดุงูุฏู ูุถุนุช ุณุฑูุณโูุง
docker compose ps

# ูุดุงูุฏู ูุงฺฏโูุง
docker compose logs -f
```

### ฺฏุงู 4: ุชุณุช ุณูุงูุช

```bash
# ุชุณุช ุณูุงูุช ฺฉู
curl https://localhost/health

# ุชุณุช ุณูุงูุช STT
curl https://localhost/stt/health

# ุชุณุช ุณูุงูุช LLM
curl https://localhost/llm/health
```

## ๐ง ุณุฑูุณโูุง ููุฌูุฏ

### 1. API Gateway (Port: 8000)

- **ููุด**: ูุฏุฑุช ูุฑฺฉุฒ ุฏุฑุฎูุงุณุชโูุง
- **URL**: https://localhost:8000
- **Endpoints**:
  - `/health` - ุจุฑุฑุณ ุณูุงูุช
  - `/api/info` - ุงุทูุงุนุงุช API
  - `/api/v1/llm/*` - ุณุฑูุณโูุง LLM
  - `/api/v1/stt/*` - ุณุฑูุณโูุง STT

### 2. LLM Service (Port: 8002)

- **ููุด**: ุชููุฏ ูุชู ุจุง ูุฏู GPT2-FA
- **URL**: https://localhost:8002
- **ูฺฺฏโูุง**: ุชููุฏ ูุชูุ ฺฏูุชฺฏูุ ูพุฑุฏุงุฒุด ุฏุณุชูโุง

### 3. STT Service (Port: 8003)

- **ููุด**: ุชุจุฏู ฺฏูุชุงุฑ ุจู ูุชู
- **URL**: https://localhost:8003
- **ูฺฺฏโูุง**:
  - ูพุดุชุจุงู ุงุฒ ูุฑูุชโูุง ูุฎุชูู ุตูุช
  - ูพุฑุฏุงุฒุด Base64 ุจุฑุง ููุจุงู
  - ูพุฑุฏุงุฒุด ุฏุณุชูโุง
  - ฺฉุด ฺฉุฑุฏู ูุชุงุฌ

### 4. GPU Coordinator (Port: 8080)

- **ููุด**: ูุฏุฑุช ูุดุชุฑฺฉ GPU
- **URL**: https://localhost:8080
- **ูฺฺฏโูุง**: ุชุฎุตุต ููุดููุฏ GPUุ ูุฏุฑุช ุตู

### 5. Monitoring

- **Prometheus**: https://localhost:9090
- **Grafana**: https://localhost:3000 (admin/admin)

## ๐งช ุชุณุช ู ุงุณุชูุงุฏู

### ุชุณุช STT Service

#### 1. ุชุณุช ุณุงุฏู ุจุง cURL

```bash
# ุขูพููุฏ ูุงู ุตูุช
curl -X POST https://localhost/api/v1/stt/transcribe \
  -F "audio_file=@test_audio.wav" \
  -F "language=fa" \
  -F "task=transcribe"

# ุจุฑุฑุณ ุฒุจุงูโูุง ูพุดุชุจุงู ุดุฏู
curl https://localhost/api/v1/stt/languages
```

#### 2. ุชุณุช ุจุง Python Client

```bash
# ูุตุจ ูุงุจุณุชฺฏโูุง
pip install aiohttp aiofiles

# ุงุฌุฑุง ุชุณุช
cd tests
python stt_test_client.py --file test_audio.wav --language fa

# ุชุณุช ฺฉุงุฑุง
python stt_test_client.py --file test_audio.wav --performance 5

# ุชุณุช ุฏุณุชูโุง
python stt_test_client.py --batch --files audio1.wav audio2.wav audio3.wav
```

#### 3. ุชุณุช Base64 (ุดุจูโุณุงุฒ ููุจุงู)

```bash
python stt_test_client.py --file test_audio.wav --base64 --language fa
```

### ุชุณุช LLM Service

```bash
# ุชููุฏ ูุชู
curl -X POST https://localhost/api/v1/llm/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "ุณูุงู", "max_length": 100, "temperature": 0.7}'

# ฺฏูุชฺฏู
curl -X POST https://localhost/api/v1/llm/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "ุณูุงูุ ุญุงูุช ฺุทูุฑูุ"}'
```

## ๐ ูุงูุชูุฑูฺฏ

### Grafana Dashboard

1. ุจุฑูุฏ ุจู https://localhost:3000
2. ูุงุฑุฏ ุดูุฏ ุจุง admin/admin
3. Dashboard ูุง ุขูุงุฏู ุฑุง ูุดุงูุฏู ฺฉูุฏ

### ูุชุฑฺฉโูุง ฺฉูุฏ

- **STT Metrics**:
  - ุชุนุฏุงุฏ ุฏุฑุฎูุงุณุชโูุง
  - ุฒูุงู ูพุฑุฏุงุฒุด
  - ูุฑุฎ ููููุช
  - ุงุณุชูุงุฏู ุงุฒ GPU
- **LLM Metrics**:
  - ุชุนุฏุงุฏ ุชููุฏ ูุชู
  - ุฒูุงู ูพุงุณุฎ
  - ุงุณุชูุงุฏู ุงุฒ ุญุงูุธู
- **GPU Metrics**:
  - ุงุณุชูุงุฏู ุงุฒ GPU
  - ุญุงูุธู ุงุดุบุงู ุดุฏู
  - ุตู ุงูุชุธุงุฑ

## ๐ง ุชูุธูุงุช ูพุดุฑูุชู

### ุชูุธู STT Service

ูุงู `services/audio-service/stt/config/stt_config.yaml`:

```yaml
stt_service:
  model:
    size: "base" # tiny, base, small, medium, large
    device: "auto" # auto, cpu, cuda
  audio:
    max_file_size: 25 # MB
    max_duration: 600 # seconds
  performance:
    max_concurrent_requests: 5
    timeout: 300
  cache:
    enabled: true
    ttl: 3600 # 1 hour
```

### ุชูุธู ูุชุบุฑูุง ูุญุท

ูุงู `.env`:

```env
# STT Configuration
WHISPER_MODEL_SIZE=base
MAX_FILE_SIZE_MB=25
MAX_CONCURRENT_REQUESTS=5
CACHE_ENABLED=true
CACHE_TTL=3600

# GPU Configuration
MAX_GPU_MEMORY_MB=6144
```

## ๐จ ุนุจโุงุจ

### ูุดฺฉูุงุช ุฑุงุฌ

#### 1. ูุฏู LLM ููุฏ ููโุดูุฏ

```bash
# ุจุฑุฑุณ ูุฌูุฏ ูุงูโูุง ูุฏู
ls -la data/models/llm/gpt2-fa/

# ุจุฑุฑุณ ูุงฺฏโูุง LLM Service
docker compose logs llm-service
```

#### 2. GPU ุชุดุฎุต ุฏุงุฏู ููโุดูุฏ

```bash
# ุจุฑุฑุณ GPU
nvidia-smi

# ุจุฑุฑุณ NVIDIA Container Toolkit
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi

# ุจุฑุฑุณ ูุงฺฏโูุง GPU Coordinator
docker compose logs gpu-coordinator
```

#### 3. STT Service ุขูุณุชู ุงุณุช

```bash
# ุจุฑุฑุณ ุงุณุชูุงุฏู ุงุฒ ููุงุจุน
docker stats

# ฺฉุงูุด ููุฒูุงู ุฏุฑุฎูุงุณุชโูุง
# ุฏุฑ .env: MAX_CONCURRENT_REQUESTS=2

# ุงุณุชูุงุฏู ุงุฒ ูุฏู ฺฉูฺฺฉุชุฑ
# ุฏุฑ .env: WHISPER_MODEL_SIZE=tiny
```

#### 4. ุฎุทุงูุง ุญุงูุธู

```bash
# ุจุฑุฑุณ ุญุงูุธู ููุฌูุฏ
free -h

# ฺฉุงูุด ุญุงูุธู ูุญุฏูุฏ ุดุฏู ุจุฑุง ุณุฑูุณโูุง
# ุฏุฑ docker-compose.ymlุ ฺฉุงูุด memory limits
```

### ูุงฺฏโูุง ู ุฏุจุงฺฏ

```bash
# ูุดุงูุฏู ูุงฺฏโูุง ุฒูุฏู
docker compose logs -f stt-service

# ูุดุงูุฏู ูุงฺฏโูุง ุฎุงุต
docker compose logs stt-service | grep ERROR

# ุจุฑุฑุณ ูุถุนุช ุณุฑูุณโูุง
docker compose ps

# ุฑโุงุณุชุงุฑุช ุณุฑูุณ ุฎุงุต
docker compose restart stt-service
```

## ๐ API Documentation

### STT Service Endpoints

#### POST /transcribe

ุขูพููุฏ ู ุชุจุฏู ูุงู ุตูุช ุจู ูุชู

```bash
curl -X POST https://localhost/api/v1/stt/transcribe \
  -F "audio_file=@audio.wav" \
  -F "language=fa" \
  -F "task=transcribe"
```

**Response:**

```json
{
  "text": "ูุชู ุชุจุฏู ุดุฏู ุงุฒ ฺฏูุชุงุฑ",
  "language": "fa",
  "confidence": 0.95,
  "duration": 15.5,
  "processing_time": 2.3,
  "segments": [...]
}
```

#### POST /transcribe-base64

ุชุจุฏู ุตุฏุง Base64 (ุจุฑุง ููุจุงู)

```bash
curl -X POST https://localhost/api/v1/stt/transcribe-base64 \
  -H "Content-Type: application/json" \
  -d '{
    "audio_data": "UklGRnbiAQBXQVZFZm...",
    "filename": "audio.wav",
    "language": "fa",
    "format": "wav"
  }'
```

#### POST /transcribe-batch

ูพุฑุฏุงุฒุด ุฏุณุชูโุง ฺูุฏู ูุงู

```bash
curl -X POST https://localhost/api/v1/stt/transcribe-batch \
  -F "files=@audio1.wav" \
  -F "files=@audio2.wav" \
  -F "files=@audio3.wav"
```

#### GET /languages

ุฏุฑุงูุช ุฒุจุงูโูุง ูพุดุชุจุงู ุดุฏู

```bash
curl https://localhost/api/v1/stt/languages
```

## ๐ ุงููุช

### ุชูุธูุงุช ุงููุช

- ุชุบุฑ ูพุณูุฑุฏูุง ูพุดโูุฑุถ ุฏุฑ production
- ูุญุฏูุฏุช CORS ุจุฑุง production
- ุงุณุชูุงุฏู ุงุฒ HTTPS
- ูุญุฏูุฏุช rate limiting
- ุงุญุฑุงุฒ ููุช ู ุงุฎุชุงุฑุงุช ฺฉุงุฑุจุฑุงู

### Production Checklist

- [ ] ุชุบุฑ JWT_SECRET_KEY
- [ ] ุชุบุฑ ูพุณูุฑุฏ ูพุงฺฏุงู ุฏุงุฏู
- [ ] ุชูุธู CORS ูุญุฏูุฏ
- [ ] ูุนุงูโุณุงุฒ HTTPS
- [ ] ุชูุธู backup ุฎูุฏฺฉุงุฑ
- [ ] ูุงูุชูุฑูฺฏ ู alerting
- [ ] ุชุณุช load testing
- [ ] ุชูุธู log rotation

## ๐ Performance Tuning

### ุจูููโุณุงุฒ STT

- ุงุณุชูุงุฏู ุงุฒ ูุฏู ููุงุณุจ (base ุจุฑุง ุชุนุงุฏู ุณุฑุนุช/ุฏูุช)
- ุชูุธู cache TTL
- ฺฉุงูุด max_concurrent_requests ุฏุฑ ุตูุฑุช ูุญุฏูุฏุช ููุงุจุน
- ุงุณุชูุงุฏู ุงุฒ GPU ุจุฑุง ุณุฑุนุช ุจุดุชุฑ

### ุจูููโุณุงุฒ GPU

- ูุฏุฑุช priority ุจุฑุง ุฏุฑุฎูุงุณุชโูุง ูุฎุชูู
- ุชูุธู memory limits ููุงุณุจ
- monitoring ุงุณุชูุงุฏู ุงุฒ GPU

### Scale Up/Out

- ุงุถุงูู ฺฉุฑุฏู replica ุจุฑุง ุณุฑูุณโูุง
- ุงุณุชูุงุฏู ุงุฒ load balancer
- database clustering
- microservices architecture

---

## ๐ ูพุดุชุจุงู

ุจุฑุง ุณูุงูุงุช ู ูุดฺฉูุงุช:

1. ุจุฑุฑุณ ุงู ุฑุงูููุง
2. ูุทุงูุนู ูุงฺฏโูุง ุณุณุชู
3. ุจุฑุฑุณ issues ุฏุฑ repository
4. ุชูุงุณ ุจุง ุชู ุชูุณุนู

**ูฺฉุชู**: ุงู ุณุณุชู ุจุฑุง ูุญุท development ุทุฑุงุญ ุดุฏู ู ุจุฑุง production ูุงุฒ ุจู ุชูุธูุงุช ุงููุช ุงุถุงู ุฏุงุฑุฏ.

---

## ๐ ูุงุณูุณ

ุงู ูพุฑูฺู ุชุญุช ูุงุณูุณ MIT ููุชุดุฑ ุดุฏู ุงุณุช.
ุฎูุงุตู ูพุงุฏูโุณุงุฒ ฺฉุงูู
ุณุณุชู Agentic AI Platform ุจุง ุณุฑูุณ STT ุจู ุตูุฑุช ฺฉุงูู ูพุงุฏูโุณุงุฒ ุดุฏ! ุฏุฑ ุงุฏุงูู ุฎูุงุตูโุง ุงุฒ ุขูฺู ุงูุฌุงู ุฏุงุฏู:
โ ุขูฺู ูพุงุฏูโุณุงุฒ ุดุฏ:
๐ฏ ุณุฑูุณ STT (Speech-to-Text)

Enhanced STT Service ุจุง Whisper ูุฏู
ูพุดุชุจุงู ุงุฒ ูุงุฑุณ ู ุงูฺฏูุณ
ูพุฑุฏุงุฒุด Base64 ุจุฑุง ููุจุงู
ูพุฑุฏุงุฒุด ุฏุณุชูโุง (Batch Processing)
ฺฉุด ฺฉุฑุฏู ูุชุงุฌ ุจุฑุง ุจูุจูุฏ ฺฉุงุฑุง
ูพุฑุฏุงุฒุด ุตูุช ูพุดุฑูุชู (noise reductionุ normalization)
ูุฏุฑุช ุฎุทุง ู retry logic

๐ฎ ูุฏุฑุช ูุดุชุฑฺฉ GPU

GPU Coordinator ุจุฑุง ุชุฎุตุต ููุดููุฏ GPU
Priority-based scheduling
Resource management ุจู LLM ู STT
Monitoring ู metrics ุจุฑุง GPU

๐ง ุจูุจูุฏูุง ุฒุฑุณุงุฎุช

Docker Compose ุจุฑูุฒุฑุณุงู ุดุฏู
Nginx ุจุง ูพุดุชุจุงู STT
API Gateway ุจุง routing ูุง STT
Configuration management ูพุดุฑูุชู
Monitoring ฺฉุงูู ุจุง Prometheus

๐ ูุงูโูุง ุงุฌุงุฏ ุดุฏู:

STT Service Core:

services/audio-service/stt/main.py - ุณุฑูุณ ุงุตู
services/audio-service/stt/Dockerfile - ุฏุงฺฉุฑ
services/audio-service/stt/requirements.txt - ูุงุจุณุชฺฏโูุง

Configuration:

services/audio-service/stt/config/stt_config.yaml
services/audio-service/stt/utils/audio_processor.py

GPU Management:

utils/gpu_coordinator.py - ูุฏุฑุช GPU ูุดุชุฑฺฉ

Infrastructure:

docker-compose.yml - ุจุฑูุฒุฑุณุงู ุดุฏู
nginx.conf - ูพฺฉุฑุจูุฏ ุฌุฏุฏ
Prometheus configs

Testing:

tests/stt_test_client.py - ฺฉูุงูุช ุชุณุช ฺฉุงูู

Documentation:

ุฑุงูููุง ฺฉุงูู ุฑุงูโุงูุฏุงุฒ ู ุงุณุชูุงุฏู

๐ ูุงุจูุชโูุง ฺฉูุฏ:
STT Service Features:
โ Multi-format Support - WAV, MP3, M4A, FLAC, OGG, WebM
โ Multilingual - ูุงุฑุณุ ุงูฺฏูุณุ ุชุดุฎุต ุฎูุฏฺฉุงุฑ
โ Mobile Ready - ูพุดุชุจุงู Base64
โ Batch Processing - ูพุฑุฏุงุฒุด ููุฒูุงู ฺูุฏู ูุงู
โ Advanced Audio Processing - noise reductionุ normalization
โ Caching System - ฺฉุด ููุดููุฏ ูุชุงุฌ
โ GPU Acceleration - ุงุณุชูุงุฏู ุจููู ุงุฒ GPU
โ Monitoring & Metrics - ูุชุฑฺฉโูุง ฺฉุงูู
GPU Coordination:
โ Shared GPU Management - ุชุฎุตุต ููุดููุฏ ุจู ุณุฑูุณโูุง
โ Priority Scheduling - ุงูููุชโุจูุฏ ุฏุฑุฎูุงุณุชโูุง
โ Resource Monitoring - ูุธุงุฑุช ุจุฑ ุงุณุชูุงุฏู ุงุฒ ููุงุจุน
โ Automatic Cleanup - ูพุงฺฉุณุงุฒ ุฎูุฏฺฉุงุฑ
๐ง ูุญูู ุงุณุชูุงุฏู:
ุฑุงูโุงูุฏุงุฒ:

# ๐ฏ ูููููโูุง ฺฉุงุฑุจุฑุฏ ุณุฑูุณ STT ูพุดุฑูุชู

## ๐ ููุงุจุน ูุฑูุฏ ูุฎุชูู

### 1. ุขูพููุฏ ูุงู ุงุฒ ูุจ ุงูพูฺฉุดู

```javascript
// Frontend JavaScript
async function uploadAudioFile(file, language = "fa", translateTo = null) {
  const formData = new FormData();
  formData.append("audio_file", file);
  formData.append("language", language);
  formData.append("task", "transcribe");

  if (translateTo) {
    formData.append("translate_to", translateTo);
  }

  try {
    const response = await fetch("/api/v1/stt/transcribe", {
      method: "POST",
      body: formData,
    });

    const result = await response.json();

    console.log("Transcribed text:", result.text);
    console.log("Language:", result.language);
    console.log("Confidence:", result.confidence);

    if (result.translation) {
      console.log("Translation:", result.translation.translated_text);
    }

    return result;
  } catch (error) {
    console.error("Transcription failed:", error);
  }
}

// ุงุณุชูุงุฏู
const fileInput = document.getElementById("audioFile");
const file = fileInput.files[0];
uploadAudioFile(file, "fa", "en"); // ูุงุฑุณ ุจู ุงูฺฏูุณ
```

### 2. ุงุฑุณุงู ุตูุช ุงุฒ ููุจุงู ุงูพ (Base64)

```javascript
// React Native / Mobile App
async function transcribeAudioFromMobile(
  audioBase64,
  filename,
  language = "fa"
) {
  const payload = {
    audio_data: audioBase64,
    filename: filename,
    language: language,
    format: "wav",
  };

  try {
    const response = await fetch("/api/v1/stt/transcribe-base64", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify(payload),
    });

    const result = await response.json();

    console.log("Mobile transcription:", result.text);
    console.log("Processing time:", result.processing_time);

    return result;
  } catch (error) {
    console.error("Mobile transcription failed:", error);
  }
}

// ุชุจุฏู ูุงู ุตูุช ุจู Base64
function audioToBase64(audioFile) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      const base64 = reader.result.split(",")[1]; // ุญุฐู header
      resolve(base64);
    };
    reader.onerror = reject;
    reader.readAsDataURL(audioFile);
  });
}

// ุงุณุชูุงุฏู
const audioFile = recordedAudio; // ูุงู ุถุจุท ุดุฏู
const base64Audio = await audioToBase64(audioFile);
transcribeAudioFromMobile(base64Audio, "recorded_audio.wav", "fa");
```

### 3. ุฏุงูููุฏ ู ุชุจุฏู ุงุฒ URL

```python
# Python Example
import requests

def transcribe_from_url(audio_url, language='auto', translate_to=None):
    """ุชุจุฏู ูุงู ุตูุช ุงุฒ URL"""

    payload = {
        "url": audio_url,
        "language": language,
        "max_file_size": 50  # 50MB
    }

    params = {}
    if translate_to:
        params["translate_to"] = translate_to

    try:
        response = requests.post(
            "https://localhost/api/v1/stt/transcribe-url",
            json=payload,
            params=params,
            timeout=300  # 5 minutes
        )

        if response.status_code == 200:
            result = response.json()

            print(f"URL: {audio_url}")
            print(f"Text: {result['text']}")
            print(f"Language: {result['language']}")
            print(f"Duration: {result['duration']:.2f}s")

            if result.get('translation'):
                print(f"Translation: {result['translation']['translated_text']}")

            return result
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None

    except Exception as e:
        print(f"Error: {e}")
        return None

# ุงุณุชูุงุฏู
# ุชุจุฏู ุงุฒ ฺฉ ูพุงุฏฺฉุณุช ูุงุฑุณ ู ุชุฑุฌูู ุจู ุงูฺฏูุณ
result = transcribe_from_url(
    "https://example.com/persian_podcast.mp3",
    language="fa",
    translate_to="en"
)
```

### 4. ุชุจุฏู ูุงู ููฺฉุงู ุณุฑูุฑ

```bash
# cURL Example
curl -X POST https://localhost/api/v1/stt/transcribe-local \
  -H "Content-Type: application/json" \
  -d '{
    "file_path": "/app/uploads/meeting_recording.wav",
    "language": "fa"
  }'

# Response:
# {
#   "text": "ูุชู ุฌูุณู ุชุจุฏู ุดุฏู...",
#   "language": "fa",
#   "confidence": 0.95,
#   "duration": 1800.0,
#   "processing_time": 45.2,
#   "source_type": "local_path"
# }
```

## ๐ ุชุฑุฌูู ุขููุงู

### 1. ุชุฑุฌูู ููุฑุงู ุจุง ุชุจุฏู ฺฏูุชุงุฑ

```python
def transcribe_and_translate(audio_file_path, source_lang="fa", target_lang="en"):
    """ุชุจุฏู ฺฏูุชุงุฑ + ุชุฑุฌูู ฺฉุฌุง"""

    with open(audio_file_path, 'rb') as f:
        files = {'audio_file': f}
        data = {
            'language': source_lang,
            'task': 'transcribe',
            'translate_to': target_lang
        }

        response = requests.post(
            "https://localhost:8003/transcribe",
            files=files,
            data=data
        )

        if response.status_code == 200:
            result = response.json()

            print("Original text:", result['text'])

            if result.get('translation') and result['translation']['success']:
                print("Translated text:", result['translation']['translated_text'])
            else:
                print("Translation failed:", result.get('translation', {}).get('error'))

            return result

# ุงุณุชูุงุฏู
transcribe_and_translate("persian_speech.wav", "fa", "en")
```

### 2. ุชุฑุฌูู ูุณุชูู ูุชู

```javascript
// Standalone Translation
async function translateText(text, sourceLang, targetLang) {
  const payload = {
    text: text,
    source_language: sourceLang,
    target_language: targetLang,
    service: "google",
  };

  try {
    const response = await fetch("/api/v1/stt/translate", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload),
    });

    const result = await response.json();

    if (result.success) {
      return result.translated_text;
    } else {
      throw new Error(result.error);
    }
  } catch (error) {
    console.error("Translation error:", error);
    return null;
  }
}

// ุงุณุชูุงุฏู
const persianText = "ุงู ฺฉ ูุชู ูุงุฑุณ ุงุณุช";
const englishText = await translateText(persianText, "fa", "en");
console.log(englishText); // "This is a Persian text"
```

## ๐ฆ ูพุฑุฏุงุฒุด ุฏุณุชูโุง

### 1. ูพุฑุฏุงุฒุด ฺูุฏู ูุงู ููุฒูุงู

```python
def batch_transcribe_files(file_paths, translate_to=None):
    """ูพุฑุฏุงุฒุด ุฏุณุชูโุง ฺูุฏู ูุงู"""

    files = []
    for file_path in file_paths:
        with open(file_path, 'rb') as f:
            files.append(('files', (file_path, f.read(), 'audio/wav')))

    data = {}
    if translate_to:
        data['translate_to'] = translate_to

    response = requests.post(
        "https://localhost:8003/transcribe-batch",
        files=files,
        data=data,
        timeout=1800  # 30 minutes
    )

    if response.status_code == 200:
        result = response.json()

        print(f"Batch Results:")
        print(f"Total: {result['summary']['total_files']}")
        print(f"Successful: {result['summary']['successful_count']}")
        print(f"Failed: {result['summary']['failed_count']}")
        print(f"Success Rate: {result['summary']['success_rate']}")

        for item in result['results']:
            if item['success']:
                print(f"โ {item['filename']}: {item['result']['text'][:50]}...")
            else:
                print(f"โ {item['filename']}: {item['error']}")

        return result
    else:
        print(f"Batch processing failed: {response.status_code}")
        return None

# ุงุณุชูุงุฏู
audio_files = [
    "meeting1.wav",
    "interview1.wav",
    "lecture1.wav"
]
batch_transcribe_files(audio_files, translate_to="en")
```

## ๐๏ธ ุณูุงุฑููุง ฺฉุงุฑุจุฑุฏ ูุงูุน

### 1. ูพูุชูุฑู ุขููุฒุด ุขููุงู

```python
class OnlineLearningPlatform:
    def __init__(self):
        self.stt_base_url = "https://localhost:8003"

    def process_lecture_recording(self, lecture_file, instructor_language="fa"):
        """ูพุฑุฏุงุฒุด ุถุจุท ุฌูุณู ุฏุฑุณ"""

        # ุชุจุฏู ฺฏูุชุงุฑ ุจู ูุชู + ุชุฑุฌูู
        with open(lecture_file, 'rb') as f:
            files = {'audio_file': f}
            data = {
                'language': instructor_language,
                'translate_to': 'en'  # ุจุฑุง ุฏุงูุดุฌูุงู ุจูโุงูููู
            }

            response = requests.post(
                f"{self.stt_base_url}/transcribe",
                files=files,
                data=data
            )

            if response.status_code == 200:
                result = response.json()

                # ุฐุฎุฑู ูุชู ูุงุฑุณ
                persian_transcript = result['text']

                # ุฐุฎุฑู ุชุฑุฌูู ุงูฺฏูุณ
                english_translation = None
                if result.get('translation', {}).get('success'):
                    english_translation = result['translation']['translated_text']

                # ุฐุฎุฑู timestamps ุจุฑุง subtitle
                segments = result.get('segments', [])

                return {
                    'persian_text': persian_transcript,
                    'english_text': english_translation,
                    'segments': segments,
                    'duration': result['duration']
                }

    def create_subtitles(self, segments, language="fa"):
        """ุงุฌุงุฏ ูุงู ุฒุฑููุณ"""

        srt_content = ""
        for i, segment in enumerate(segments):
            start_time = self.seconds_to_srt_time(segment['start'])
            end_time = self.seconds_to_srt_time(segment['end'])
            text = segment['text'].strip()

            srt_content += f"{i+1}\n"
            srt_content += f"{start_time} --> {end_time}\n"
            srt_content += f"{text}\n\n"

        return srt_content

    def seconds_to_srt_time(self, seconds):
        """ุชุจุฏู ุซุงูู ุจู ูุฑูุช SRT"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)

        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

# ุงุณุชูุงุฏู
platform = OnlineLearningPlatform()
lecture_data = platform.process_lecture_recording("physics_lecture.wav", "fa")

# ุงุฌุงุฏ ุฒุฑููุณ ูุงุฑุณ
persian_srt = platform.create_subtitles(lecture_data['segments'], "fa")
with open("lecture_fa.srt", "w", encoding="utf-8") as f:
    f.write(persian_srt)
```

### 2. ุณุณุชู ูุฏุฑุช ุชูุงุณ ูุดุชุฑุงู

```python
class CallCenterManager:
    def __init__(self):
        self.stt_url = "https://localhost:8003"

    def process_customer_call(self, call_recording_url, customer_language="fa"):
        """ูพุฑุฏุงุฒุด ุชูุงุณ ูุดุชุฑ"""

        # ุฏุงูููุฏ ู ุชุจุฏู ุงุฒ URL
        payload = {
            "url": call_recording_url,
            "language": customer_language,
            "max_file_size": 100  # 100MB ุจุฑุง ุชูุงุณโูุง ุทููุงู
        }

        params = {"translate_to": "en"}  # ุชุฑุฌูู ุจุฑุง ุขูุงูุฒ

        response = requests.post(
            f"{self.stt_url}/transcribe-url",
            json=payload,
            params=params
        )

        if response.status_code == 200:
            result = response.json()

            return {
                'call_transcript': result['text'],
                'call_translation': result.get('translation', {}).get('translated_text'),
                'call_duration': result['duration'],
                'call_language': result['language'],
                'processing_time': result['processing_time']
            }

    def analyze_customer_sentiment(self, transcript):
        """ุขูุงูุฒ ุงุญุณุงุณุงุช ูุดุชุฑ (ููููู)"""
        # ุงูุฌุง ูโุชููุฏ ุงุฒ ุณุฑูุณโูุง ุขูุงูุฒ ุงุญุณุงุณุงุช ุงุณุชูุงุฏู ฺฉูุฏ
        positive_words = ['ุฎูุจ', 'ุนุงู', 'ุฑุงุถ', 'ููููู']
        negative_words = ['ุจุฏ', 'ูุดฺฉู', 'ูุงุฑุงุถ', 'ุดฺฉุงุช']

        positive_count = sum(1 for word in positive_words if word in transcript)
        negative_count = sum(1 for word in negative_words if word in transcript)

        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"

# ุงุณุชูุงุฏู
call_center = CallCenterManager()
call_data = call_center.process_customer_call(
    "https://storage.example.com/calls/call_123.mp3",
    "fa"
)

sentiment = call_center.analyze_customer_sentiment(call_data['call_transcript'])
print(f"Customer sentiment: {sentiment}")
```

### 3. ุณุณุชู ุงุฏุฏุงุดุชโุจุฑุฏุงุฑ ููุดููุฏ

```javascript
// Smart Note-Taking System
class SmartNoteTaker {
  constructor() {
    this.baseUrl = "/api/v1/stt";
  }

  async recordAndTranscribe(
    audioBlob,
    meetingLanguage = "fa",
    translateTo = "en"
  ) {
    // ุชุจุฏู audio blob ุจู base64
    const base64Audio = await this.blobToBase64(audioBlob);

    const payload = {
      audio_data: base64Audio,
      filename: `meeting_${Date.now()}.wav`,
      language: meetingLanguage,
      format: "wav",
    };

    const params = translateTo ? `?translate_to=${translateTo}` : "";

    try {
      const response = await fetch(
        `${this.baseUrl}/transcribe-base64${params}`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(payload),
        }
      );

      const result = await response.json();

      return {
        transcript: result.text,
        translation: result.translation?.translated_text,
        segments: result.segments,
        confidence: result.confidence,
        language: result.language,
      };
    } catch (error) {
      console.error("Recording transcription failed:", error);
      throw error;
    }
  }

  async blobToBase64(blob) {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const base64 = reader.result.split(",")[1];
        resolve(base64);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }

  generateSummary(segments) {
    // ุฎูุงุตูโุณุงุฒ ุณุงุฏู ุจุฑ ุงุณุงุณ ุทููุงูโุชุฑู ุฌููุงุช
    const longSegments = segments
      .filter((seg) => seg.text.length > 50)
      .sort((a, b) => b.confidence - a.confidence)
      .slice(0, 5);

    return longSegments.map((seg) => seg.text).join(" ");
  }
}

// ุงุณุชูุงุฏู ุฏุฑ ุงูพูฺฉุดู
const noteTaker = new SmartNoteTaker();

// ุถุจุท ู ุชุจุฏู ุฏุฑ ุฌูุณู
navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
  const mediaRecorder = new MediaRecorder(stream);
  const audioChunks = [];

  mediaRecorder.ondataavailable = (event) => {
    audioChunks.push(event.data);
  };

  mediaRecorder.onstop = async () => {
    const audioBlob = new Blob(audioChunks, { type: "audio/wav" });

    try {
      const result = await noteTaker.recordAndTranscribe(audioBlob, "fa", "en");

      // ููุงุด ูุชุงุฌ
      document.getElementById("transcript").innerText = result.transcript;
      document.getElementById("translation").innerText = result.translation;

      // ุงุฌุงุฏ ุฎูุงุตู
      const summary = noteTaker.generateSummary(result.segments);
      document.getElementById("summary").innerText = summary;
    } catch (error) {
      console.error("Error:", error);
    }
  };

  // ุดุฑูุน ุถุจุท
  mediaRecorder.start();

  // ุชููู ุจุนุฏ ุงุฒ 30 ุซุงูู (ูุซุงู)
  setTimeout(() => {
    mediaRecorder.stop();
    stream.getTracks().forEach((track) => track.stop());
  }, 30000);
});
```

## ๐ง ูฺฉุงุช ุจูููโุณุงุฒ

### 1. ุงูุชุฎุงุจ ูุฏู ููุงุณุจ

```bash
# ุจุฑุง ุณุฑุนุช ุจุดุชุฑ (ููุงุณุจ real-time)
WHISPER_MODEL_SIZE=tiny

# ุจุฑุง ุชุนุงุฏู ุณุฑุนุช/ุฏูุช (ูพุดููุงุฏ)
WHISPER_MODEL_SIZE=base

# ุจุฑุง ุฏูุช ุจุงูุง (ููุงุณุจ ูุญุชูุง ููู)
WHISPER_MODEL_SIZE=large
```

### 2. ูุฏุฑุช ุญุงูุธู

```python
# ูพุฑุฏุงุฒุด ูุงูโูุง ุจุฒุฑฺฏ ุจู ุตูุฑุช ุชฺฉูโุง
def process_large_audio(file_path, chunk_duration=30):
    """ูพุฑุฏุงุฒุด ูุงูโูุง ุตูุช ุจุฒุฑฺฏ"""

    # ุชูุณู ูุงู ุจู ุจุฎุดโูุง ฺฉูฺฺฉุชุฑ
    # ู ูพุฑุฏุงุฒุด ุฌุฏุงฺฏุงูู ูุฑ ุจุฎุด

    results = []
    # ูพุงุฏูโุณุงุฒ ุชูุณูโุจูุฏ...

    return results
```

### 3. ฺฉุด ฺฉุฑุฏู ูุชุงุฌ

```python
import hashlib

def get_audio_hash(audio_content):
    """ุงุฌุงุฏ hash ุจุฑุง ูุงู ุตูุช"""
    return hashlib.md5(audio_content).hexdigest()

def cached_transcribe(audio_file, language="fa"):
    """ุชุจุฏู ุจุง ฺฉุด"""

    with open(audio_file, 'rb') as f:
        content = f.read()

    audio_hash = get_audio_hash(content)
    cache_key = f"stt_{audio_hash}_{language}"

    # ุจุฑุฑุณ cache
    # ุงฺฏุฑ ูุฌูุฏ ุฏุงุดุชุ return ฺฉู
    # ุฏุฑ ุบุฑ ุงู ุตูุฑุชุ ูพุฑุฏุงุฒุด ฺฉู ู cache ฺฉู
```

ุงู ุณุณุชู ุญุงูุง ูุงุจูุช ูพุฑุฏุงุฒุด ุตูุช ุงุฒ ููุงุจุน ูุฎุชูู ู ุชุฑุฌูู ุขููุงู ุฑุง ุฏุงุฑุฏ! ๐

๐ฏ ุฎูุงุตู ฺฉุงูู ุณุณุชู STT ูพุดุฑูุชู
โ ูุงุจูุชโูุง ุฌุฏุฏ ุงุถุงูู ุดุฏู:
๐ต ููุงุจุน ูุฑูุฏ ูุชููุน:

File Upload - ุขูพููุฏ ูุณุชูู ูุงู (ูุจ ุงูพูฺฉุดู)
Base64 Audio - ูพุฑุฏุงุฒุด ุตูุช ฺฉุฏฺฏุฐุงุฑ ุดุฏู (ููุจุงู ุงูพ)
URL Download - ุฏุงูููุฏ ู ูพุฑุฏุงุฒุด ุงุฒ ููฺฉ
Local File Path - ูพุฑุฏุงุฒุด ูุงูโูุง ููฺฉุงู ุณุฑูุฑ

๐ ุชุฑุฌูู ุขููุงู:

ุชุฑุฌูู ุฎูุฏฺฉุงุฑ ููุฑุงู ุจุง ุชุจุฏู ฺฏูุชุงุฑ
ูพุดุชุจุงู ุงุฒ Google Translate
ุชุฑุฌูู ูุณุชูู ูุชู
ุชุฑุฌูู ุฏุณุชูโุง

๐ง ูฺฺฏโูุง ูพุดุฑูุชู:

Enhanced Error Handling - ูุฏุฑุช ุฎุทุง ุจูุจูุฏ ุงูุชู
Multiple Format Support - WAV, MP3, M4A, FLAC, OGG, WebM, AAC
Confidence Scoring - ุงูุชุงุฒ ุงุทููุงู ุจุฑุง ูุฑ ุจุฎุด
Segment Timestamps - ุฒูุงูโุจูุฏ ุฏูู ุจุฑุง ุฒุฑููุณ
Comprehensive Logging - ูุงฺฏโฺฏุฑ ฺฉุงูู
Performance Monitoring - ูุธุงุฑุช ุจุฑ ฺฉุงุฑุง

๐ API Endpoints ุฌุฏุฏ:

---

---

---

# ุฑุงูููุง ฺฉุงูู ุณุฑูุณ STT - ุชุจุฏู ฺฏูุชุงุฑ ุจู ูุชู

## ๐ฏ ูุนุฑู ุณุฑูุณ

ุณุฑูุณ STT ุดูุง ฺฉ ุณุฑูุณ ูพุดุฑูุชู ุจุฑุง ุชุจุฏู ฺฏูุชุงุฑ ุจู ูุชู ุงุณุช ฺฉู ุงุฒ ูุฏู Whisper ุงุณุชูุงุฏู ูโฺฉูุฏ ู ุงูฺฉุงูุงุช ุฒุฑ ุฑุง ุงุฑุงุฆู ูโุฏูุฏ:

- **4 ุฑูุด ูุฎุชูู ูุฑูุฏ** ุจุฑุง ูุงูโูุง ุตูุช
- **ุชุฑุฌูู ุขููุงู** ูุชู ุชุจุฏู ุดุฏู
- **ูพุฑุฏุงุฒุด ุฏุณุชูโุง** ฺูุฏู ูุงู ููุฒูุงู
- **ูพุดุชุจุงู ุงุฒ ูุฑูุชโูุง ูุฎุชูู** ุตูุช
- **ุจูููโุณุงุฒ GPU** ุจุฑุง ุณุฑุนุช ุจุงูุง

---

## ๐ ุฑุงูโุงูุฏุงุฒ ุณุฑูุณ

### ูพุดโูุงุฒูุง

```bash
# ูุตุจ dependencies
pip install -r requirements.txt

# ูุชุบุฑูุง ูุญุท ููู
export WHISPER_MODEL_SIZE="base"  # tiny, base, small, medium, large
export WHISPER_MODEL_PATH="/app/models"
export MAX_FILE_SIZE_MB="25"
export GPU_ENABLED="true"
```

### ุงุฌุฑุง ุณุฑูุณ

```bash
# ูุณุชููุงู
python services/audio-service/stt/main.py

# ุง ุจุง uvicorn
uvicorn main:app --host 0.0.0.0 --port 8003 --reload

# ุง ุงุฒ ุทุฑู API Gateway
# ุณุฑูุณ ุฏุฑ http://localhost:8000/api/v1/stt ุฏุฑ ุฏุณุชุฑุณ ุงุณุช
```

---

## ๐ ูุฑูุชโูุง ูพุดุชุจุงู ุดุฏู

### ูุฑูุชโูุง ุตูุช

- **WAV** (.wav) - ุจูุชุฑู ฺฉูุช
- **MP3** (.mp3) - ุฑุงุฌโุชุฑู ูุฑูุช
- **M4A** (.m4a) - ูุฑูุช Apple
- **FLAC** (.flac) - ูุดุฑุฏูโุณุงุฒ ุจุฏูู ุงุชูุงู
- **OGG** (.ogg) - ูุฑูุช ูุชูโุจุงุฒ
- **WebM** (.webm) - ูุฑูุช ูุจ
- **AAC** (.aac) - ูุฑูุช ูพุดุฑูุชู

### ูุญุฏูุฏุชโูุง ูุงู

- **ุญุฏุงฺฉุซุฑ ุงูุฏุงุฒู**: 25MB (ูุงุจู ุชูุธู)
- **ุญุฏุงฺฉุซุฑ ูุฏุช**: 10 ุฏููู (600 ุซุงูู)
- **ูุฑุฎ ูููููโุจุฑุฏุงุฑ ุจููู**: 16kHz
- **ฺฉุงูุงู**: ูููู (ุชฺฉโฺฉุงูุงู) ุชุฑุฌุญ ุฏุงุฏู ูโุดูุฏ

---

## ๐ API Endpoints ู ูุญูู ุงุณุชูุงุฏู

### 1. ุขูพููุฏ ูุณุชูู ูุงู (File Upload)

**ููุงุณุจ ุจุฑุง**: ุฑุงุจุทโูุง ูุจุ ุจุฑูุงููโูุง ุฏุณฺฉุชุงูพ

```bash
# ุงุณุชูุงุฏู ุจุง curl
curl -X POST "http://localhost:8003/transcribe" \
  -F "audio_file=@/path/to/your/audio.wav" \
  -F "language=fa" \
  -F "translate_to=en"

# ุง ุงุฒ ุทุฑู API Gateway
curl -X POST "http://localhost:8000/api/v1/stt/transcribe" \
  -F "audio_file=@/path/to/audio.mp3" \
  -F "language=auto"
```

**ูพุงุฑุงูุชุฑูุง:**

- `audio_file`: ูุงู ุตูุช (ุงุฌุจุงุฑ)
- `language`: ุฒุจุงู ููุจุน (`fa`, `en`, `auto`) - ุงุฎุชุงุฑ
- `task`: `transcribe` ุง `translate` - ูพุดโูุฑุถ `transcribe`
- `translate_to`: ุฒุจุงู ููุตุฏ ุจุฑุง ุชุฑุฌูู (`fa`, `en`) - ุงุฎุชุงุฑ

**ูพุงุณุฎ ููููู:**

```json
{
  "text": "ุณูุงูุ ุงู ฺฉ ุชุณุช ุตูุช ุงุณุช",
  "language": "fa",
  "confidence": 0.95,
  "duration": 3.2,
  "processing_time": 1.8,
  "source_type": "file_upload",
  "segments": [
    {
      "start": 0.0,
      "end": 3.2,
      "text": "ุณูุงูุ ุงู ฺฉ ุชุณุช ุตูุช ุงุณุช",
      "confidence": 0.95
    }
  ],
  "translation": {
    "service": "google",
    "source_language": "fa",
    "target_language": "en",
    "translated_text": "Hello, this is an audio test",
    "success": true
  }
}
```

### 2. ูพุฑุฏุงุฒุด Base64 (ููุจุงู ุงูพโูุง)

**ููุงุณุจ ุจุฑุง**: ุงูพูฺฉุดูโูุง ููุจุงูุ PWA

```python
import base64
import requests

# ุชุจุฏู ูุงู ุตูุช ุจู base64
with open("audio.wav", "rb") as f:
    audio_base64 = base64.b64encode(f.read()).decode()

# ุงุฑุณุงู ุฏุฑุฎูุงุณุช
payload = {
    "audio_data": audio_base64,
    "filename": "audio.wav",
    "language": "fa",
    "format": "wav"
}

response = requests.post(
    "http://localhost:8003/transcribe-base64",
    json=payload,
    params={"translate_to": "en"}
)
```

### 3. ุฏุงูููุฏ ุงุฒ URL

**ููุงุณุจ ุจุฑุง**: ูุงูโูุง ุขููุงูุ ุงุณุชุฑูโูุง

```python
import requests

payload = {
    "url": "https://example.com/audio.mp3",
    "language": "auto",
    "max_file_size": 50  # MB
}

response = requests.post(
    "http://localhost:8003/transcribe-url",
    json=payload
)
```

### 4. ูุงู ูุญู (ุณุฑูุฑ)

**ููุงุณุจ ุจุฑุง**: ูุงูโูุง ุฏุงุฎู ุณุฑูุฑ

```python
import requests

payload = {
    "file_path": "/app/uploads/audio.wav",
    "language": "fa"
}

response = requests.post(
    "http://localhost:8003/transcribe-local",
    json=payload
)
```

### 5. ูพุฑุฏุงุฒุด ุฏุณุชูโุง (Batch)

**ููุงุณุจ ุจุฑุง**: ูพุฑุฏุงุฒุด ฺูุฏู ูุงู ููุฒูุงู

```bash
curl -X POST "http://localhost:8003/transcribe-batch" \
  -F "files=@audio1.wav" \
  -F "files=@audio2.mp3" \
  -F "files=@audio3.m4a" \
  -F "translate_to=en"
```

---

## ๐ ุชุฑุฌูู ุขููุงู

ุณุฑูุณ ุงูฺฉุงู ุชุฑุฌูู ุฎูุฏฺฉุงุฑ ูุชู ุชุจุฏู ุดุฏู ุฑุง ุฏุงุฑุฏ:

```python
# ุชุฑุฌูู ูุณุชูู
payload = {
    "text": "ุณูุงู ุฏูุง",
    "source_language": "fa",
    "target_language": "en",
    "service": "google"
}

response = requests.post(
    "http://localhost:8003/translate",
    json=payload
)
```

---

## ๐ ูุซุงูโูุง ุนูู

### ูุซุงู 1: ุงูพูฺฉุดู ูุจ ุณุงุฏู

```html
<!DOCTYPE html>
<html>
  <body>
    <input type="file" id="audioFile" accept="audio/*" />
    <button onclick="transcribe()">ุชุจุฏู ุจู ูุชู</button>
    <div id="result"></div>

    <script>
      async function transcribe() {
        const fileInput = document.getElementById("audioFile");
        const file = fileInput.files[0];

        const formData = new FormData();
        formData.append("audio_file", file);
        formData.append("language", "fa");
        formData.append("translate_to", "en");

        const response = await fetch(
          "http://localhost:8000/api/v1/stt/transcribe",
          {
            method: "POST",
            body: formData,
          }
        );

        const result = await response.json();
        document.getElementById("result").innerHTML = `<p>ูุงุฑุณ: ${
          result.text
        }</p>
             <p>English: ${result.translation?.translated_text || "N/A"}</p>`;
      }
    </script>
  </body>
</html>
```

### ูุซุงู 2: ุงูพูฺฉุดู ููุจุงู (React Native)

```javascript
import { Audio } from "expo-av";
import * as FileSystem from "expo-file-system";

const recordAndTranscribe = async () => {
  // ุถุจุท ุตุฏุง
  const recording = new Audio.Recording();
  await recording.prepareToRecordAsync(
    Audio.RECORDING_OPTIONS_PRESET_HIGH_QUALITY
  );
  await recording.startAsync();

  // ุชููู ุถุจุท
  setTimeout(async () => {
    await recording.stopAndUnloadAsync();
    const uri = recording.getURI();

    // ุชุจุฏู ุจู base64
    const base64 = await FileSystem.readAsStringAsync(uri, {
      encoding: FileSystem.EncodingType.Base64,
    });

    // ุงุฑุณุงู ุจู ุณุฑูุณ
    const response = await fetch(
      "http://your-server:8000/api/v1/stt/transcribe-base64",
      {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          audio_data: base64,
          filename: "recording.m4a",
          language: "fa",
          format: "m4a",
        }),
      }
    );

    const result = await response.json();
    console.log("ูุชุฌู:", result.text);
  }, 5000);
};
```

### ูุซุงู 3: ุงุณฺฉุฑูพุช ูพุงุชูู

```python
#!/usr/bin/env python3
import requests
import os
from pathlib import Path

def process_audio_folder(folder_path, output_file="results.txt"):
    """ูพุฑุฏุงุฒุด ุชูุงู ูุงูโูุง ุตูุช ุฏุฑ ฺฉ ูพูุดู"""

    audio_extensions = ['.wav', '.mp3', '.m4a', '.flac', '.ogg']
    results = []

    for file_path in Path(folder_path).iterdir():
        if file_path.suffix.lower() in audio_extensions:
            print(f"ูพุฑุฏุงุฒุด {file_path.name}...")

            with open(file_path, 'rb') as f:
                files = {'audio_file': f}
                data = {'language': 'auto', 'translate_to': 'en'}

                response = requests.post(
                    'http://localhost:8000/api/v1/stt/transcribe',
                    files=files,
                    data=data
                )

                if response.status_code == 200:
                    result = response.json()
                    results.append({
                        'file': file_path.name,
                        'text': result['text'],
                        'translation': result.get('translation', {}).get('translated_text', 'N/A'),
                        'confidence': result['confidence'],
                        'duration': result['duration']
                    })
                    print(f"โ {file_path.name} ูพุฑุฏุงุฒุด ุดุฏ")
                else:
                    print(f"โ ุฎุทุง ุฏุฑ {file_path.name}: {response.text}")

    # ุฐุฎุฑู ูุชุงุฌ
    with open(output_file, 'w', encoding='utf-8') as f:
        for result in results:
            f.write(f"=== {result['file']} ===\n")
            f.write(f"ูุชู ูุงุฑุณ: {result['text']}\n")
            f.write(f"English: {result['translation']}\n")
            f.write(f"ุงุนุชูุงุฏ: {result['confidence']:.2f}\n")
            f.write(f"ูุฏุช: {result['duration']:.1f}s\n\n")

    print(f"ูุชุงุฌ ุฏุฑ {output_file} ุฐุฎุฑู ุดุฏ")

if __name__ == "__main__":
    process_audio_folder("./audio_files")
```

---

## โ๏ธ ุชูุธูุงุช ู ุจูููโุณุงุฒ

### ูุชุบุฑูุง ูุญุท ููู

```bash
# ุงูุฏุงุฒู ูุฏู Whisper
WHISPER_MODEL_SIZE=base  # tiny=ุณุฑุน, large=ุฏูู

# GPU
CUDA_VISIBLE_DEVICES=0

# ูุญุฏูุฏุชโูุง
MAX_FILE_SIZE_MB=25
MAX_AUDIO_DURATION=600
MAX_CONCURRENT_REQUESTS=5

# ฺฉุด
CACHE_ENABLED=true
CACHE_TTL=3600

# ุชุฑุฌูู
TRANSLATION_SERVICE=google
```

### ูุงู ูพฺฉุฑุจูุฏ (stt_config.yaml)

```yaml
stt_service:
  model:
    size: "base" # tiny, base, small, medium, large
    device: "auto" # auto, cpu, cuda

  audio:
    max_file_size: 25 # MB
    max_duration: 600 # seconds

  processing:
    normalize_audio: true
    remove_silence: true
    enhance_audio: true
```

---

## ๐ ูุงูุชูุฑูฺฏ ู ุนุจโุงุจ

### ุจุฑุฑุณ ุณูุงูุช ุณุฑูุณ

```bash
# ุจุฑุฑุณ ุณูุงูุช ฺฉู
curl http://localhost:8003/health

# ุจุฑุฑุณ ุฒุจุงูโูุง ูพุดุชุจุงู ุดุฏู
curl http://localhost:8003/languages

# ุงุฒ ุทุฑู API Gateway
curl http://localhost:8000/api/v1/stt/health
```

### ูุงฺฏโูุง ููุฏ

```bash
# ูุดุงูุฏู ูุงฺฏโูุง
tail -f /app/logs/stt.log

# ุง ุฏุฑ ุตูุฑุช ุงุฌุฑุง ูุณุชูู
python main.py  # ูุงฺฏโูุง ุฏุฑ ฺฉูุณูู ููุงุด ุฏุงุฏู ูโุดููุฏ
```

### ุฑูุน ูุดฺฉูุงุช ูุชุฏุงูู

1. **ุฎุทุง "Model not loaded"**

   ```bash
   # ุจุฑุฑุณ ูุถุง ุฏุณฺฉ
   df -h
   # ุฏุงูููุฏ ูุฌุฏุฏ ูุฏู
   rm -rf /app/models && python main.py
   ```

2. **ุฎุทุง "CUDA out of memory"**

   ```bash
   # ุงุณุชูุงุฏู ุงุฒ ูุฏู ฺฉูฺฺฉโุชุฑ
   export WHISPER_MODEL_SIZE=tiny
   # ุง ุงุณุชูุงุฏู ุงุฒ CPU
   export WHISPER_MODEL_DEVICE=cpu
   ```

3. **ุฎุทุง "File too large"**
   ```bash
   # ุงูุฒุงุด ูุญุฏูุฏุช
   export MAX_FILE_SIZE_MB=50
   ```

---

## ๐ฏ ูฺฉุงุช ุจูููโุณุงุฒ

### ุจุฑุง ุจูุชุฑู ฺฉูุช:

- ุงุฒ ูุฑูุช WAV ุจุง 16kHz ุงุณุชูุงุฏู ฺฉูุฏ
- ุตุฏุง ูุงุถุญ ู ุจุฏูู ููุฒ ุถุจุท ฺฉูุฏ
- ุงุฒ `language=auto` ุจุฑุง ุชุดุฎุต ุฎูุฏฺฉุงุฑ ุฒุจุงู
- ูุฏู `large` ุจุฑุง ุฏูุช ุจุงูุง

### ุจุฑุง ุจูุชุฑู ุณุฑุนุช:

- ุงุฒ ูุฏู `tiny` ุง `base` ุงุณุชูุงุฏู ฺฉูุฏ
- ูุงูโูุง ฺฉูุชุงูโุชุฑ (ุฒุฑ 30 ุซุงูู) ุงุฑุณุงู ฺฉูุฏ
- ุงุฒ GPU ุงุณุชูุงุฏู ฺฉูุฏ
- ฺฉุด ุฑุง ูุนุงู ูฺฏู ุฏุงุฑุฏ

### ุจุฑุง ุจุฑูุงููโูุง ุชููุฏ:

- Rate limiting ูพุงุฏูโุณุงุฒ ฺฉูุฏ
- Authentication ุงุถุงูู ฺฉูุฏ
- ูุงฺฏโฺฏุฑ ู ูุงูุชูุฑูฺฏ ุชูุธู ฺฉูุฏ
- HTTPS ุงุณุชูุงุฏู ฺฉูุฏ

---

## ๐ ูุซุงู ฺฉุงุฑุจุฑุฏูุง ุนูู

1. **ุฑุจุงุช ุถุจุท ุฌูุณุงุช**: ุถุจุท ู ูุชูโุณุงุฒ ุฌูุณุงุช
2. **ุงูพ ุงุฏฺฏุฑ ุฒุจุงู**: ุชุดุฎุต ุชููุธ ู ุชุตุญุญ
3. **ุณุณุชู ูพุงุณุฎฺฏู**: ุชุจุฏู ุณูุงูุงุช ุตูุช ุจู ูุชู
4. **ุฒุฑููุณ ุฎูุฏฺฉุงุฑ**: ุชููุฏ ุฒุฑููุณ ุจุฑุง ูุฏุฆููุง
5. **ุฏุณุชุงุฑ ุตูุช**: ูพุฑุฏุงุฒุด ูุฑูุงูโูุง ุตูุช

ุงู ุณุฑูุณ STT ุจุณุงุฑ ูุฏุฑุชููุฏ ู ุงูุนุทุงูโูพุฐุฑ ุงุณุช ู ูโุชูุงูุฏ ูุงุฒูุง ูุฎุชูู ูพุฑุฏุงุฒุด ฺฏูุชุงุฑ ุจู ูุชู ุฑุง ูพูุดุด ุฏูุฏ!

--------------------run
docker build -t stt-service .
